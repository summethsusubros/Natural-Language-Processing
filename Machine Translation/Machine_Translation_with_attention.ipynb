{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine_Translation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6AWgTZFRicF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from attention import AttentionLayer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bXLAxCQC0fl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing libraries\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "from numpy import array, argmax \n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, LSTM, Embedding,TimeDistributed ,Input \n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "pd.set_option('display.max_colwidth', 200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2Rj-2c5fgJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset=pd.read_table('/content/Machine-Translation/deu.txt',names=['english_text','german_text','link'])\n",
        "dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53rr4giibt3Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3lYAR4ggKuE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpPiFKZ0gKqx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = dataset[['english_text', 'german_text']]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfquLje1BHjX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "\n",
        "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mu-fqroQgKoA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocessing english text\n",
        "cleaned_english_text = dataset.english_text.map(lambda x : x.lower())\n",
        "cleaned_english_text = cleaned_english_text.map(lambda x : ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in x.split(\" \")]))\n",
        "cleaned_english_text = cleaned_english_text.map(lambda x : re.sub(r\"'s\\b\",'',x))\n",
        "cleaned_english_text = cleaned_english_text.map(lambda x : re.sub(r'[^a-zA-Z]', ' ', x))\n",
        "cleaned_english_text = cleaned_english_text.map(lambda x : ' '.join([w for w in x.split()])) #for removing multiple spaces together\n",
        "\n",
        "print(cleaned_english_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O38z1htGofjz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocessing english text\n",
        "table = str.maketrans(string.punctuation, ' '*len(string.punctuation), string.digits)\n",
        "cleaned_german_text = dataset.german_text.map(lambda x : x.lower())\n",
        "cleaned_german_text = cleaned_german_text.map(lambda x : x.translate(table))\n",
        "cleaned_german_text = cleaned_german_text.map(lambda x : ' '.join([w for w in x.split()])) #for removing multiple spaces together\n",
        "cleaned_german_text = cleaned_german_text.map(lambda x : 'starttoken ' + x + ' endtoken')\n",
        "\n",
        "print(cleaned_german_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yyu5vapHgKe-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset['cleaned_english_text'] = cleaned_english_text\n",
        "dataset['cleaned_german_text'] = cleaned_german_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2BxY12ZgKcc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Displaying first five lines from preprocessed dataset\n",
        "for i in range(len(dataset)-10,len(dataset)):\n",
        "  print('English :' ,cleaned_english_text[i] )\n",
        "  print('German :' ,cleaned_german_text[i])\n",
        "  print('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BULSmBYngKaC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Finding the length of text\n",
        "english_word_count = dataset['cleaned_english_text'].map(lambda x : len(x.split()))\n",
        "dataset['english_word_count'] = english_word_count\n",
        "english_word_count.max()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxtwlFgagKXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Finding the length of heaadlines\n",
        "german_word_count = dataset['cleaned_german_text'].map(lambda x : len(x.split()))\n",
        "dataset['german_word_count'] = german_word_count\n",
        "german_word_count.max()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PB5UWQQFvBvd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "english_length=101 #max length of english sentence\n",
        "german_length=78   #max length of german sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veis2QUQvG7M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train test split\n",
        "x_train, x_test, y_train, y_test = train_test_split(dataset['cleaned_english_text'], dataset['cleaned_german_text'], test_size=0.2,random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5XAyTbM8PYF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_tokenizer = Tokenizer()\n",
        "x_tokenizer.fit_on_texts(list(x_train))\n",
        "\n",
        "x_train    =   x_tokenizer.texts_to_sequences(x_train) \n",
        "x_test   =   x_tokenizer.texts_to_sequences(x_test)\n",
        "\n",
        "x_train    =   pad_sequences(x_train,  maxlen=english_length) \n",
        "x_test   =   pad_sequences(x_test, maxlen=english_length)\n",
        "\n",
        "english_vocab_size   =  len(x_tokenizer.word_index) +1\n",
        "english_vocab_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI6dr17R8oPr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_tokenizer = Tokenizer()\n",
        "y_tokenizer.fit_on_texts(list(y_train))\n",
        "\n",
        "y_train    =   y_tokenizer.texts_to_sequences(y_train) \n",
        "y_test   =   y_tokenizer.texts_to_sequences(y_test) \n",
        "\n",
        "y_train    =   pad_sequences(y_train, maxlen=german_length)\n",
        "y_test   =   pad_sequences(y_test, maxlen=german_length)\n",
        "\n",
        "german_vocab_size  =   len(y_tokenizer.word_index) +1\n",
        "german_vocab_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3vkhBT_f3Qh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "latent_dim = 101\n",
        "embedding_dimension = 256\n",
        "epochs =10\n",
        "batch_size = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20UG26c9zkid",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K \n",
        "K.clear_session() \n",
        "\n",
        "encoder_inputs = Input(shape=(english_length,), name='encoder_inputs_layer')\n",
        "\n",
        "encoder_embedding_layer= Embedding(english_vocab_size, embedding_dimension, mask_zero= True ,name='encoder_embedding_layer')\n",
        "encoder_embedding = encoder_embedding_layer(encoder_inputs)\n",
        "\n",
        "encoder_lstm_layer = LSTM(latent_dim , return_sequences = True ,return_state = True , name = 'encoder_lstm_layer')\n",
        "encoder_outputs, encoder_state_h, encoder_state_c = encoder_lstm_layer(encoder_embedding)\n",
        "\n",
        "decoder_inputs = Input(shape=(None,), name = 'decoder_inputs_layer')\n",
        "\n",
        "decoder_embedding_layer= Embedding(german_vocab_size, embedding_dimension,mask_zero= True , name = 'decoder_embedding_layer')\n",
        "decoder_embedding = decoder_embedding_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm_layer = LSTM(latent_dim, return_sequences=True, return_state = True , name = 'decoder_lstm_layer' )\n",
        "decoder_outputs, decoder_state_h, decoder_state_c = decoder_lstm_layer(decoder_embedding ,initial_state = [encoder_state_h, encoder_state_c])\n",
        "\n",
        "attn_layer = AttentionLayer(name='attention_layer')\n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
        "\n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "decoder_dense_layer = TimeDistributed(Dense(german_vocab_size, activation='softmax' , name = 'decoder_dense_layer'))\n",
        "decoder_dense_layer_outputs = decoder_dense_layer(decoder_concat_input)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_dense_layer_outputs) \n",
        "model.summary(250)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olc_zPY8k7aj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model compiling\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgaLA2OvwHL1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klw4G9UX1pUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history=model.fit([x_train,y_train[:,:-1]], y_train.reshape(y_train.shape[0],y_train.shape[1], 1)[:,1:] ,epochs=epochs,callbacks=[es],batch_size=batch_size, validation_data=([x_test,y_test[:,:-1]], y_test.reshape(y_test.shape[0],y_test.shape[1], 1)[:,1:]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujRFvrUA19R_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# epochs loss function\n",
        "from matplotlib import pyplot \n",
        "pyplot.plot(history.history['loss'], label='train') \n",
        "pyplot.plot(history.history['val_loss'], label='test') \n",
        "pyplot.legend() \n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlhWCj2B0Gzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "reverse_target_word_index = y_tokenizer.index_word \n",
        "reverse_source_word_index = x_tokenizer.index_word \n",
        "target_word_index = y_tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ot0r5flGnjzs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(reverse_target_word_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-EYn5fLgMXx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encoder inference\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, encoder_state_h, encoder_state_c])\n",
        "encoder_model.summary(250)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7ZVsa_51Wi5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# decoder inference\n",
        "decoder_state_input_h = Input(shape=(latent_dim,), name= 'decoder_state_input_h')\n",
        "decoder_state_input_c = Input(shape=(latent_dim,), name= 'decoder_state_input_c')\n",
        "decoder_hidden_state_input = Input(shape=(english_length,latent_dim), name= 'decoder_hidden_state_input')\n",
        "\n",
        "decoder_embedding_2= decoder_embedding_layer(decoder_inputs)\n",
        "\n",
        "decoder_outputs2, decoder_state_h2, decoder_state_c2 = decoder_lstm_layer(decoder_embedding_2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "attention_layer_inf = Attention(name='attention_layer_inf')\n",
        "attention_out_inf, attention_states_inf = attention_layer_inf([decoder_hidden_state_input, decoder_outputs2])\n",
        "\n",
        "decoder_inf_concat = concatenate(axis=-1, name='concat')([decoder_outputs2, attention_out_inf])\n",
        "\n",
        "decoder_outputs2 = decoder_dense_layer(decoder_inf_concat)\n",
        "\n",
        "decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c], [decoder_outputs2] + [decoder_state_h2, decoder_state_c2])\n",
        "decoder_model.summary(250)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0gLj97mLrbC5",
        "colab": {}
      },
      "source": [
        "def sequence_to_sentance(input_sequence):\n",
        "\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_sequence)\n",
        "\n",
        "    target_seq = np.zeros((1,1))\n",
        "    target_seq[0, 0] = target_word_index['starttoken']\n",
        "\n",
        "    decoded_sentence = ''\n",
        "    stop_condition = False\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        predicted_token_index = np.argmax(output_tokens[:])\n",
        "        predicted_token = reverse_target_word_index[predicted_token_index]\n",
        "\n",
        "        if(predicted_token!='endtoken'):\n",
        "            decoded_sentence += ' '+predicted_token\n",
        "\n",
        "        if (predicted_token == 'endtoken' or len(decoded_sentence.split()) >= (german_length-1)):\n",
        "            stop_condition = True\n",
        "\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = predicted_token_index\n",
        "\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJIHTO3I1a_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sequence_to_german(input_sequence):\n",
        "    text=''\n",
        "    for i in input_sequence:\n",
        "      if((i!=0 and i!=target_word_index['starttoken']) and i!=target_word_index['endtoken']):\n",
        "        text=text+reverse_target_word_index[i]+' '\n",
        "    return text\n",
        "\n",
        "def sequence_to_english(input_sequence):\n",
        "    text=''\n",
        "    for i in input_sequence:\n",
        "      if(i!=0):\n",
        "        text=text+reverse_source_word_index[i]+' '\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBx-DRTZ1eJs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(5,10):\n",
        "  print(\"English:\",sequence_to_english(x_test[i]))\n",
        "  print(\"Original German:\",sequence_to_german(y_test[i]))\n",
        "  print(\"Predicted German:\",sequence_to_sentance(x_test[i].reshape(1,english_length)))\n",
        "  print(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uS9v610r5XsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}