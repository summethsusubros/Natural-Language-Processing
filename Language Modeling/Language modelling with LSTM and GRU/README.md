# Language Modeling

## Language Model

In simple words, language modelling(LM) refers to estimation of the relative likelihood of the appearence of a phrase or a sentence.

In this project, we build LM using RNNs, LSTMs and GRUs to make character and word level language models

## Dataset
Here we use a plain text data of a story book. You can clone this repo to get it. 

## Resources required
-Numpy

-Pandas

-sklearn

-re

-Tensorflow keras

## How do we do this?
We use the recurrent neural network (RNN), which made many NLP tasks possible and had been the building block of the present State-of-Art model of NLP.
RNN ,LSTM and GRU are a class of neural nets which are most suitable for dealig with sequence data.
