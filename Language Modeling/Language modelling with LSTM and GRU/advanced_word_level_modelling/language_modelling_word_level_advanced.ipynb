{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "language_modelling_word_level_advanced.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWIu5BLF1z_X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importing required libraries.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import regexp_tokenize \n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "from nltk.tokenize import sent_tokenize \n",
        "\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, GRU, SimpleRNN, Dense, Embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oetkK0tdEHwS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Dictionary for contraction mapping.\n",
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "\n",
        "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xqMrg0SVKpF",
        "colab_type": "text"
      },
      "source": [
        "STEP-1:Importing the dataset and preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npvTQ9dasJ_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading the dataset.\n",
        "sample = open(\"/content/example.txt\", \"r\") \n",
        "s = sample.read() \n",
        "  \n",
        "text = s.replace(\"\\n\", \" \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqzWD8WM2Zbp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5TSQZAYF4yw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Removing the contraction words.\n",
        "text = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in text.split(\" \")])    \n",
        "text = re.sub(r\"'s\\b\",\"\",text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HB2_Ttg2agv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Tokenizing the sentence into sentences.\n",
        "sentences=sent_tokenize(text) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Wb1vWxB5vqQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Forming a dataframe with sentences.\n",
        "data={'sentences':sentences}\n",
        "sentences_df=pd.DataFrame(data)\n",
        "sentences_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqMYKYj64pSm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Preprocessing the text data.\n",
        "def preprocessor (sentence):\n",
        "  #converting the text to lower case.\n",
        "  sentence=sentence.map(lambda s : s.lower())\n",
        "  #Tokenizing the text data.\n",
        "  sentence=sentence.map(lambda s : regexp_tokenize(s,'[a-zA-Z]+'))\n",
        "  #Detokenizing the tokens to fprm the text data.\n",
        "  sentence=sentence.map(lambda s : TreebankWordDetokenizer().detokenize(s))\n",
        "  return sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yw3Qn47I5Kxm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocessed_sentences = preprocessor(sentences_df['sentences'])\n",
        "preprocessed_sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vvVMh2qVkx9",
        "colab_type": "text"
      },
      "source": [
        "STEP-2:Formation of word sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReXHNYBWCR8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Removing sentences with words less than the sequence length.\n",
        "#The sequence length is set to 5.\n",
        "length=5\n",
        "preprocessed_long_sentences=[]\n",
        "for i in preprocessed_sentences:\n",
        "  if(len(i.split())>length-1):\n",
        "    preprocessed_long_sentences.append(i)\n",
        "preprocessed_long_sentences\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lfEXkXR8jq1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Word sequence formation.\n",
        "sequence=[]\n",
        "for sent in preprocessed_long_sentences:\n",
        "  for i in range(0,len(sent.split())+1-length):\n",
        "    seq=sent.split()[i:i+length]\n",
        "    sequence.append(seq)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDgyOkErIhHS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2RzTBYYpFJ4",
        "colab_type": "text"
      },
      "source": [
        "STEP-3:Building encoding dictionary and encoding the word sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_H9LNYW5NEis",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Forming the a text only with the long sentences.\n",
        "text=' '.join(i for i in preprocessed_long_sentences)\n",
        "text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amv8Df4x-hvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Building encoder dictionary.\n",
        "word = sorted(list(set(text.split())))\n",
        "encoder_dictionary = dict((c, i) for i, c in enumerate(word))\n",
        "word "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lg9CZGzN_PGJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_dictionary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB6Nhfd8_VsE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab=len(encoder_dictionary)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0C3i82X_m_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Encoding the word sequence.\n",
        "encoded_sequence = []\n",
        "for i in sequence:\n",
        "  seq=[encoder_dictionary[j] for j in i]\n",
        "  encoded_sequence.append(seq)  \n",
        "encoded_sequence = np.array(encoded_sequence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9P0mhr7_q6F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAp_RDRSpYFx",
        "colab_type": "text"
      },
      "source": [
        "STEP-4:Train test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6yiSzF5_vsW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Last element of the encoded sequence is considered as the target value(y) of the preceding sequence(x).\n",
        "x = encoded_sequence[:,:-1]\n",
        "y = encoded_sequence[:,-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4w9-QWb_5vC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#One-hot encoder.\n",
        "y = to_categorical(y, num_classes=vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1u6jgby_8QI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Train test split.\n",
        "X_tr, X_val, y_tr, y_val = train_test_split(x, y, test_size=0.2, random_state=63)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llazMNzLpusW",
        "colab_type": "text"
      },
      "source": [
        "Step-5:Building the SimpleRNN, LSTM, GRU models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkE8lfiCACWZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define SimpleRNN model.\n",
        "SimpleRNN_model = Sequential()\n",
        "SimpleRNN_model.add(Embedding(vocab, 50, input_length=length-1, trainable=True))\n",
        "SimpleRNN_model.add(SimpleRNN(150, recurrent_dropout=0.1, dropout=0.1))\n",
        "SimpleRNN_model.add(Dense(vocab, activation='softmax'))\n",
        "print(SimpleRNN_model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XwYx8lgAGlJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Compile the SimpleRNN model.\n",
        "SimpleRNN_model.compile(loss='categorical_crossentropy', metrics=['acc'], optimizer='adam')\n",
        "SimpleRNN_model.fit(X_tr, y_tr, epochs=50, verbose=2, validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vx1uRTEcAJJT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define LSTM model.\n",
        "LSTM_model = Sequential()\n",
        "LSTM_model.add(Embedding(vocab, 50, input_length=length-1, trainable=True))\n",
        "LSTM_model.add(LSTM(150, recurrent_dropout=0.1, dropout=0.1))\n",
        "LSTM_model.add(Dense(vocab, activation='softmax'))\n",
        "print(LSTM_model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iegjIE4vALyt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Compile the LSTM model.\n",
        "LSTM_model.compile(loss='categorical_crossentropy', metrics=['acc'], optimizer='adam')\n",
        "LSTM_model.fit(X_tr, y_tr, epochs=50, verbose=2, validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Thy2rDASAPNe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define GRU model.\n",
        "GRU_model = Sequential()\n",
        "GRU_model.add(Embedding(vocab, 50, input_length=length-1, trainable=True))\n",
        "GRU_model.add(GRU(150, recurrent_dropout=0.1, dropout=0.1))\n",
        "GRU_model.add(Dense(vocab, activation='softmax'))\n",
        "print(GRU_model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGDyFbQvASsI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile the GRU model\n",
        "GRU_model.compile(loss='categorical_crossentropy', metrics=['acc'], optimizer='adam')\n",
        "GRU_model.fit(X_tr, y_tr, epochs=50, verbose=2, validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouetI0yeqfpE",
        "colab_type": "text"
      },
      "source": [
        "STEP-6:Text sequence generation and testing the models.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-y_bMHqvm5Lp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Generate a sequence of words with a language model.\n",
        "def generate_seq(model, encoder_dictionary, seqence_length, input_text, no_of_words_to_be_generated):\n",
        "\tin_text = input_text.lower().split()\n",
        "\t#Generate a fixed number of words.\n",
        "\tfor i in range(no_of_words_to_be_generated):\n",
        "\t\t#Encode the words as integers.\n",
        "\t\tencoded = [encoder_dictionary[word] for word in in_text]\n",
        "\t\t#Truncate sequences to a fixed length.\n",
        "\t\tencoded = pad_sequences([encoded], maxlen=seqence_length, truncating='pre')\n",
        "\t\t#Predict words.\n",
        "\t\typred = model.predict_classes(encoded, verbose=0)\n",
        "\t\t#Reverse map integer to word\n",
        "\t\tout_word = []\n",
        "\t\tfor word, index in encoder_dictionary.items():\n",
        "\t\t\tif index == ypred:\n",
        "\t\t\t\tout_word = word\n",
        "\t\t\t\tbreak\n",
        "\t\t#Append to input\n",
        "\t\tin_text.append(out_word)\n",
        "\treturn ' '.join(tokens for tokens in in_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ASHISA2WHbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SimpleRNN model testing.\n",
        "inp = 'since'\n",
        "print(generate_seq(SimpleRNN_model, encoder_dictionary,length-1,inp,14))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etPVtAmjAewM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#LSTM model testing.\n",
        "inp = 'what'\n",
        "print(generate_seq(LSTM_model, encoder_dictionary,length-1,inp,8))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzpF4hh3Aj8F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#GRU model testing.\n",
        "inp = 'my love'\n",
        "print(generate_seq(GRU_model, encoder_dictionary,length-1,inp,8))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}