{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "language_modeling_char_level.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOe3LiC7Se4n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importing required libraries.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.tokenize import regexp_tokenize \n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, GRU, SimpleRNN, Dense, Embedding\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjIwopmKewaX",
        "colab_type": "text"
      },
      "source": [
        "STEP-1:Importing the dataset and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTzMVns3g1-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading the dataset.\n",
        "sample = open(\"/content/text_data.txt\", \"r\") \n",
        "s = sample.read() \n",
        "text = s.replace(\"\\n\", \" \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zq8iOkSbjLM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Preprocessing the text data.\n",
        "def text_preprocessing(text):\n",
        "  #Converting the text to lower case and removing the begining and end spaces.\n",
        "  preprocessed_text = text.strip().lower()\n",
        "  #Tokenizing the text data.\n",
        "  preprocessed_text = regexp_tokenize(preprocessed_text,'[a-zA-Z]+')\n",
        "  #Detokenizing the tokens.\n",
        "  preprocessed_text = TreebankWordDetokenizer().detokenize(preprocessed_text)\n",
        "  return preprocessed_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Si7q5L7_aC67",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text=text_preprocessing(text)\n",
        "text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ja8wsZ0ckElZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0_fZJU7gFL6",
        "colab_type": "text"
      },
      "source": [
        "STEP-2:Formation of character sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIyYtWl9cfJ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Character sequence formation.\n",
        "sequence=[]\n",
        "#Sequence length is set to 50.\n",
        "length=50\n",
        "for i in range(0,len(text)+1-length):\n",
        "  seq=text[i:i+length]\n",
        "  sequence.append(seq)\n",
        "sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueEXIzW3mHCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(sequence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWcKe98qgnWB",
        "colab_type": "text"
      },
      "source": [
        "STEP-3:Building encoding dictionary and encoding the character sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7K4_He0dnjjo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Building encoder dictionary.\n",
        "chars = sorted(list(set(text)))\n",
        "encoder_dictionary = dict((c, i) for i, c in enumerate(chars))\n",
        "chars  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RYvRMSnqWOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_dictionary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwUrpJmybJWR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab=len(encoder_dictionary)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3am9KFt3q_M7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Encoding the character sequence.\n",
        "encoded_sequence = []\n",
        "for i in sequence:\n",
        "  seq=[encoder_dictionary[j] for j in i]\n",
        "  encoded_sequence.append(seq)  \n",
        "encoded_sequence = np.array(encoded_sequence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rjcc7uKM1E_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zv6MCcIihS9V",
        "colab_type": "text"
      },
      "source": [
        "STEP-4:Train test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aj4FNyhS20vF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Last element of the encoded sequence is considered as the target value(y) of the preceding sequence(x).\n",
        "x = encoded_sequence[:,:-1]\n",
        "y = encoded_sequence[:,-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVAPSruTWN5h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#One-hot encoder.\n",
        "y = to_categorical(y, num_classes=vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkYckOAw20ef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Train test split.\n",
        "X_tr, X_val, y_tr, y_val = train_test_split(x, y, test_size=0.2, random_state=63)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Q65eeFJhq00",
        "colab_type": "text"
      },
      "source": [
        "Step-5:Building the SimpleRNN, LSTM, GRU models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4cxRJwCkP6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define SimpleRNN model.\n",
        "SimpleRNN_model = Sequential()\n",
        "SimpleRNN_model.add(Embedding(vocab, 50, input_length=length-1, trainable=True))\n",
        "SimpleRNN_model.add(SimpleRNN(150, recurrent_dropout=0.1, dropout=0.1))\n",
        "SimpleRNN_model.add(Dense(vocab, activation='softmax'))\n",
        "print(SimpleRNN_model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyUGzorckeuV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Compile the SimpleRNN model.\n",
        "SimpleRNN_model.compile(loss='categorical_crossentropy', metrics=['acc'], optimizer='adam')\n",
        "SimpleRNN_model.fit(X_tr, y_tr, epochs=3, verbose=2, validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKllQUOshanI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define LSTM model.\n",
        "LSTM_model = Sequential()\n",
        "LSTM_model.add(Embedding(vocab, 50, input_length=length-1, trainable=True))\n",
        "LSTM_model.add(LSTM(150, recurrent_dropout=0.1, dropout=0.1))\n",
        "LSTM_model.add(Dense(vocab, activation='softmax'))\n",
        "print(LSTM_model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjvLWoYnhg23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Compile the LSTM model.\n",
        "LSTM_model.compile(loss='categorical_crossentropy', metrics=['acc'], optimizer='adam')\n",
        "LSTM_model.fit(X_tr, y_tr, epochs=10, verbose=2, validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_iysVAt53AC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define GRU model.\n",
        "GRU_model = Sequential()\n",
        "GRU_model.add(Embedding(vocab, 50, input_length=length-1, trainable=True))\n",
        "GRU_model.add(GRU(150, recurrent_dropout=0.1, dropout=0.1))\n",
        "GRU_model.add(Dense(vocab, activation='softmax'))\n",
        "print(GRU_model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpKW6mzmN6Jf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Compile the GRU model.\n",
        "GRU_model.compile(loss='categorical_crossentropy', metrics=['acc'], optimizer='adam')\n",
        "GRU_model.fit(X_tr, y_tr, epochs=3, verbose=2, validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7ixhhW8jcf4",
        "colab_type": "text"
      },
      "source": [
        "STEP-6:Text sequence generation and tesing the models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ont1K6SsWFvr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Generate a sequence of characters with a language model.\n",
        "def generate_seq(model, encoder_dictionary, seqence_length, input_text, no_of_chars_to_be_generated):\n",
        "\tin_text = input_text\n",
        "\t#generate a fixed number of characters.\n",
        "\tfor i in range(no_of_chars_to_be_generated):\n",
        "\t\t#Encode the characters as integers.\n",
        "\t\tencoded = [encoder_dictionary[char] for char in in_text]\n",
        "\t\t#Truncate sequences to a fixed length.\n",
        "\t\tencoded = pad_sequences([encoded], maxlen=seqence_length, truncating='pre')\n",
        "\t\t#Predict character.\n",
        "\t\typred = model.predict_classes(encoded, verbose=0)\n",
        "\t\t#Reverse map integer to character.\n",
        "\t\tout_char = ''\n",
        "\t\tfor char, index in encoder_dictionary.items():\n",
        "\t\t\tif index == ypred:\n",
        "\t\t\t\tout_char = char\n",
        "\t\t\t\tbreak\n",
        "\t\t#Append to input.\n",
        "\t\tin_text += char\n",
        "\treturn in_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoMpXIDnlDhE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SimpleRNN model testing.\n",
        "inp = 'the'\n",
        "print(generate_seq(SimpleRNN_model, encoder_dictionary,length-1,inp.lower(),20))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8HmkAn_iTfv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#LSTM model testing.\n",
        "inp = 'the '\n",
        "print(generate_seq(LSTM_model, encoder_dictionary,length-1,inp.lower(),20))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fS5pYE0bWMB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#GRU model testing.\n",
        "inp = 'they'\n",
        "print(generate_seq(GRU_model, encoder_dictionary,length-1,inp.lower(),20))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}