{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "language_modeling_word_level.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dn7KFykYgBc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importing required libraries.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import regexp_tokenize \n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, GRU, SimpleRNN, Dense, Embedding\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQ-8Sa-5n3hW",
        "colab_type": "text"
      },
      "source": [
        "STEP-1:Importing the dataset and preprocessing\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npvTQ9dasJ_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading the dataset.\n",
        "sample = open(\"/content/219-0.txt\", \"r\") \n",
        "s = sample.read()  \n",
        "text = s.replace(\"\\n\", \" \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EG6jarb59W43",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Preprocessing the text data.\n",
        "def text_preprocessing(text):\n",
        "  #Converting the text to lower case and removing the begining and end spaces.\n",
        "  preprocessed_text = text.strip().lower()\n",
        "  #Tokenizing the text data.\n",
        "  preprocessed_text = regexp_tokenize(preprocessed_text,'[a-zA-Z]+')\n",
        "  #Detokenizing the tokens.\n",
        "  preprocessed_text = TreebankWordDetokenizer().detokenize(preprocessed_text)\n",
        "  return preprocessed_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOfXSZ9O9ase",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text=text_preprocessing(text)\n",
        "text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBx98w-q9uZ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(text.split())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goXODWBGokUO",
        "colab_type": "text"
      },
      "source": [
        "STEP-2:Formation of word sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFEnUpLw9fal",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Word sequence formation.\n",
        "sequence=[]\n",
        "#Sequence length is set to 5.\n",
        "length=5\n",
        "for i in range(0,len(text.split())+1-length):\n",
        "  seq=text.split()[i:i+length]\n",
        "  sequence.append(seq)\n",
        "sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2RzTBYYpFJ4",
        "colab_type": "text"
      },
      "source": [
        "STEP-3:Building encoding dictionary and encoding the word sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amv8Df4x-hvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Building encoder dictionary.\n",
        "word = sorted(list(set(text.split())))\n",
        "encoder_dictionary = dict((c, i) for i, c in enumerate(word))\n",
        "word "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lg9CZGzN_PGJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_dictionary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB6Nhfd8_VsE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab=len(encoder_dictionary)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0C3i82X_m_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Encoding the word sequence.\n",
        "encoded_sequence = []\n",
        "for i in sequence:\n",
        "  seq=[encoder_dictionary[j] for j in i]\n",
        "  encoded_sequence.append(seq)  \n",
        "encoded_sequence = np.array(encoded_sequence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9P0mhr7_q6F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAp_RDRSpYFx",
        "colab_type": "text"
      },
      "source": [
        "STEP-4:Train test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6yiSzF5_vsW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Last element of the encoded sequence is considered as the target value(y) of the preceding sequence(x).\n",
        "x = encoded_sequence[:,:-1]\n",
        "y = encoded_sequence[:,-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4w9-QWb_5vC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#One-hot encoder.\n",
        "y = to_categorical(y, num_classes=vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1u6jgby_8QI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Train test split.\n",
        "X_tr, X_val, y_tr, y_val = train_test_split(x, y, test_size=0.2, random_state=63)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llazMNzLpusW",
        "colab_type": "text"
      },
      "source": [
        "Step-5:Building the SimpleRNN, LSTM, GRU models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkE8lfiCACWZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define SimpleRNN model.\n",
        "SimpleRNN_model = Sequential()\n",
        "SimpleRNN_model.add(Embedding(vocab, 50, input_length=length-1, trainable=True))\n",
        "SimpleRNN_model.add(SimpleRNN(150, recurrent_dropout=0.1, dropout=0.1))\n",
        "SimpleRNN_model.add(Dense(vocab, activation='softmax'))\n",
        "print(SimpleRNN_model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XwYx8lgAGlJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Compile the SimpleRNN model.\n",
        "SimpleRNN_model.compile(loss='categorical_crossentropy', metrics=['acc'], optimizer='adam')\n",
        "SimpleRNN_model.fit(X_tr, y_tr, epochs=20, verbose=2, validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vx1uRTEcAJJT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define LSTM model.\n",
        "LSTM_model = Sequential()\n",
        "LSTM_model.add(Embedding(vocab, 50, input_length=length-1, trainable=True))\n",
        "LSTM_model.add(LSTM(150, recurrent_dropout=0.1, dropout=0.1))\n",
        "LSTM_model.add(Dense(vocab, activation='softmax'))\n",
        "print(LSTM_model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iegjIE4vALyt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Compile the LSTM model.\n",
        "LSTM_model.compile(loss='categorical_crossentropy', metrics=['acc'], optimizer='adam')\n",
        "LSTM_model.fit(X_tr, y_tr, epochs=100, verbose=2, validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Thy2rDASAPNe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define GRU model.\n",
        "GRU_model = Sequential()\n",
        "GRU_model.add(Embedding(vocab, 50, input_length=length-1, trainable=True))\n",
        "GRU_model.add(GRU(150, recurrent_dropout=0.1, dropout=0.1))\n",
        "GRU_model.add(Dense(vocab, activation='softmax'))\n",
        "print(GRU_model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGDyFbQvASsI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile the GRU model\n",
        "GRU_model.compile(loss='categorical_crossentropy', metrics=['acc'], optimizer='adam')\n",
        "GRU_model.fit(X_tr, y_tr, epochs=20, verbose=2, validation_data=(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouetI0yeqfpE",
        "colab_type": "text"
      },
      "source": [
        "STEP-6:Text sequence generation and testing the models.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-y_bMHqvm5Lp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Generate a sequence of words with a language model.\n",
        "def generate_seq(model, encoder_dictionary, seqence_length, input_text, no_of_words_to_be_generated):\n",
        "\tin_text = input_text.lower().split()\n",
        "\t#Generate a fixed number of words.\n",
        "\tfor i in range(no_of_words_to_be_generated):\n",
        "\t\t#Encode the words as integers.\n",
        "\t\tencoded = [encoder_dictionary[word] for word in in_text]\n",
        "\t\t#Truncate sequences to a fixed length.\n",
        "\t\tencoded = pad_sequences([encoded], maxlen=seqence_length, truncating='pre')\n",
        "\t\t#Predict words.\n",
        "\t\typred = model.predict_classes(encoded, verbose=0)\n",
        "\t\t#Reverse map integer to word\n",
        "\t\tout_word = []\n",
        "\t\tfor word, index in encoder_dictionary.items():\n",
        "\t\t\tif index == ypred:\n",
        "\t\t\t\tout_word = word\n",
        "\t\t\t\tbreak\n",
        "\t\t#Append to input\n",
        "\t\tin_text.append(out_word)\n",
        "\treturn ' '.join(tokens for tokens in in_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ASHISA2WHbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SimpleRNN model testing.\n",
        "inp = 'my love'\n",
        "print(generate_seq(SimpleRNN_model, encoder_dictionary,length-1,inp,14))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etPVtAmjAewM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#LSTM model testing.\n",
        "inp = 'what'\n",
        "print(generate_seq(LSTM_model, encoder_dictionary,length-1,inp,8))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzpF4hh3Aj8F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#GRU model testing.\n",
        "inp = 'my love'\n",
        "print(generate_seq(GRU_model, encoder_dictionary,length-1,inp,8))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}